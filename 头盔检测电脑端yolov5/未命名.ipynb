{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "assumed-world",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nankai02/yolov5-4.0\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "from os import getcwd\n",
    "\n",
    "sets = ['train', 'val', 'test']\n",
    "classes = [\"cyclist\",\"hat\",\"person\",\"helmet\"]   # 改成自己的类别\n",
    "abs_path = os.getcwd()\n",
    "print(abs_path)\n",
    "\n",
    "def convert(size, box):\n",
    "    dw = 1. / (size[0])\n",
    "    dh = 1. / (size[1])\n",
    "    x = (box[0] + box[1]) / 2.0 - 1\n",
    "    y = (box[2] + box[3]) / 2.0 - 1\n",
    "    w = box[1] - box[0]\n",
    "    h = box[3] - box[2]\n",
    "    x = x * dw\n",
    "    w = w * dw\n",
    "    y = y * dh\n",
    "    h = h * dh\n",
    "    return x, y, w, h\n",
    "\n",
    "def convert_annotation(image_id):\n",
    "    in_file = open('/home/nankai02/yolov5-4.0/paper_data/Annotations/%s.xml' % (image_id), encoding='UTF-8')\n",
    "    out_file = open('/home/nankai02/yolov5-4.0/paper_data/labels/%s.txt' % (image_id), 'w')\n",
    "    tree = ET.parse(in_file)\n",
    "    root = tree.getroot()\n",
    "    size = root.find('size')\n",
    "    w = int(size.find('width').text)\n",
    "    h = int(size.find('height').text)\n",
    "    for obj in root.iter('object'):\n",
    "        # difficult = obj.find('difficult').text\n",
    "        #difficult = obj.find('Difficult').text\n",
    "        cls = obj.find('name').text\n",
    "        #if cls not in classes or int(difficult) == 1:\n",
    "         #   continue\n",
    "        cls_id = classes.index(cls)\n",
    "        xmlbox = obj.find('bndbox')\n",
    "        b = (float(xmlbox.find('xmin').text), float(xmlbox.find('xmax').text), float(xmlbox.find('ymin').text),\n",
    "             float(xmlbox.find('ymax').text))\n",
    "        b1, b2, b3, b4 = b\n",
    "        # 标注越界修正\n",
    "        if b2 > w:\n",
    "            b2 = w\n",
    "        if b4 > h:\n",
    "            b4 = h\n",
    "        b = (b1, b2, b3, b4)\n",
    "        bb = convert((w, h), b)\n",
    "        out_file.write(str(cls_id) + \" \" + \" \".join([str(a) for a in bb]) + '\\n')\n",
    "\n",
    "wd = getcwd()\n",
    "for image_set in sets:\n",
    "    if not os.path.exists('/home/nankai02/yolov5-4.0/paper_data/labels/'):\n",
    "        os.makedirs('/home/nankai02/yolov5-4.0/paper_data/labels/')\n",
    "    image_ids = open('/home/nankai02/yolov5-4.0/paper_data/ImageSets/Main/%s.txt' % (image_set)).read().strip().split()\n",
    "    list_file = open('paper_data/%s.txt' % (image_set), 'w')\n",
    "    for image_id in image_ids:\n",
    "        list_file.write(abs_path + '/paper_data/images/%s.jpg\\n' % (image_id))\n",
    "        convert_annotation(image_id)\n",
    "    list_file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-introduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from os import getcwd\n",
    "\n",
    "sets=[('2007', 'train'), ('2007', 'val'), ('2007', 'test')]\n",
    "\n",
    "classes = [\"crack\"]\n",
    "\n",
    "\n",
    "def convert_annotation(year, image_id, list_file):\n",
    "    in_file = open('VOCdevkit/VOC%s/Annotations/%s.xml'%(year, image_id))\n",
    "    tree=ET.parse(in_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    for obj in root.iter('object'):\n",
    "        difficult = obj.find('difficult').text\n",
    "        cls = obj.find('name').text\n",
    "        if cls not in classes or int(difficult)==1:\n",
    "            continue\n",
    "        cls_id = classes.index(cls)\n",
    "        xmlbox = obj.find('bndbox')\n",
    "        b = (int(xmlbox.find('xmin').text), int(xmlbox.find('ymin').text), int(xmlbox.find('xmax').text), int(xmlbox.find('ymax').text))\n",
    "        list_file.write(\" \" + \",\".join([str(a) for a in b]) + ',' + str(cls_id))\n",
    "\n",
    "wd = getcwd()\n",
    "\n",
    "for year, image_set in sets:\n",
    "    image_ids = open('VOCdevkit/VOC%s/ImageSets/Main/%s.txt'%(year, image_set)).read().strip().split()\n",
    "    list_file = open('%s_%s.txt'%(year, image_set), 'w')\n",
    "    for image_id in image_ids:\n",
    "        list_file.write('%s/VOCdevkit/VOC%s/JPEGImages/%s.jpg'%(wd, year, image_id))\n",
    "        convert_annotation(year, image_id, list_file)\n",
    "        list_file.write('\\n')\n",
    "    list_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "narrative-plastic",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "a must be greater than 0 unless no samples are taken",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d35ca30b79e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"paper_data/train.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mkmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO_Kmeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtxt2clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-d35ca30b79e9>\u001b[0m in \u001b[0;36mtxt2clusters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtxt2clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mall_boxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtxt2boxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkmeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlexsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult2txt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-d35ca30b79e9>\u001b[0m in \u001b[0;36mkmeans\u001b[0;34m(self, boxes, k, dist)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         clusters = boxes[np.random.choice(\n\u001b[0;32m---> 44\u001b[0;31m             box_number, k, replace=False)]  # init k clusters\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: a must be greater than 0 unless no samples are taken"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class YOLO_Kmeans:\n",
    "\n",
    "    def __init__(self, cluster_number, filename):\n",
    "        self.cluster_number = cluster_number\n",
    "        self.filename = \"paper_data/train.txt\"\n",
    "\n",
    "    def iou(self, boxes, clusters):  # 1 box -> k clusters\n",
    "        n = boxes.shape[0]\n",
    "        k = self.cluster_number\n",
    "\n",
    "        box_area = boxes[:, 0] * boxes[:, 1]\n",
    "        box_area = box_area.repeat(k)\n",
    "        box_area = np.reshape(box_area, (n, k))\n",
    "\n",
    "        cluster_area = clusters[:, 0] * clusters[:, 1]\n",
    "        cluster_area = np.tile(cluster_area, [1, n])\n",
    "        cluster_area = np.reshape(cluster_area, (n, k))\n",
    "\n",
    "        box_w_matrix = np.reshape(boxes[:, 0].repeat(k), (n, k))\n",
    "        cluster_w_matrix = np.reshape(np.tile(clusters[:, 0], (1, n)), (n, k))\n",
    "        min_w_matrix = np.minimum(cluster_w_matrix, box_w_matrix)\n",
    "\n",
    "        box_h_matrix = np.reshape(boxes[:, 1].repeat(k), (n, k))\n",
    "        cluster_h_matrix = np.reshape(np.tile(clusters[:, 1], (1, n)), (n, k))\n",
    "        min_h_matrix = np.minimum(cluster_h_matrix, box_h_matrix)\n",
    "        inter_area = np.multiply(min_w_matrix, min_h_matrix)\n",
    "\n",
    "        result = inter_area / (box_area + cluster_area - inter_area)\n",
    "        return result\n",
    "\n",
    "    def avg_iou(self, boxes, clusters):\n",
    "        accuracy = np.mean([np.max(self.iou(boxes, clusters), axis=1)])\n",
    "        return accuracy\n",
    "\n",
    "    def kmeans(self, boxes, k, dist=np.median):\n",
    "        box_number = boxes.shape[0]\n",
    "        distances = np.empty((box_number, k))\n",
    "        last_nearest = np.zeros((box_number,))\n",
    "        np.random.seed()\n",
    "        clusters = boxes[np.random.choice(\n",
    "            box_number, k, replace=False)]  # init k clusters\n",
    "        while True:\n",
    "\n",
    "            distances = 1 - self.iou(boxes, clusters)\n",
    "\n",
    "            current_nearest = np.argmin(distances, axis=1)\n",
    "            if (last_nearest == current_nearest).all():\n",
    "                break  # clusters won't change\n",
    "            for cluster in range(k):\n",
    "                clusters[cluster] = dist(  # update clusters\n",
    "                    boxes[current_nearest == cluster], axis=0)\n",
    "\n",
    "            last_nearest = current_nearest\n",
    "\n",
    "        return clusters\n",
    "\n",
    "    def result2txt(self, data):\n",
    "        f = open(\"data/yolo_anchors.txt\", 'w')\n",
    "        row = np.shape(data)[0]\n",
    "        for i in range(row):\n",
    "            if i == 0:\n",
    "                x_y = \"%d,%d\" % (data[i][0], data[i][1])\n",
    "            else:\n",
    "                x_y = \", %d,%d\" % (data[i][0], data[i][1])\n",
    "            f.write(x_y)\n",
    "        f.close()\n",
    "\n",
    "    def txt2boxes(self):\n",
    "        f = open(self.filename, 'r')\n",
    "        dataSet = []\n",
    "        for line in f:\n",
    "            infos = line.split(\" \")\n",
    "            length = len(infos)\n",
    "            for i in range(1, length):\n",
    "                width = int(infos[i].split(\",\")[2]) - \\\n",
    "                    int(infos[i].split(\",\")[0])\n",
    "                height = int(infos[i].split(\",\")[3]) - \\\n",
    "                    int(infos[i].split(\",\")[1])\n",
    "                dataSet.append([width, height])\n",
    "        result = np.array(dataSet)\n",
    "        f.close()\n",
    "        return result\n",
    "\n",
    "    def txt2clusters(self):\n",
    "        all_boxes = self.txt2boxes()\n",
    "        result = self.kmeans(all_boxes, k=self.cluster_number)\n",
    "        result = result[np.lexsort(result.T[0, None])]\n",
    "        self.result2txt(result)\n",
    "        print(\"K anchors:\\n {}\".format(result))\n",
    "        print(\"Accuracy: {:.2f}%\".format(\n",
    "            self.avg_iou(all_boxes, result) * 100))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cluster_number = 9\n",
    "    filename = \"paper_data/train.txt\"\n",
    "    kmeans = YOLO_Kmeans(cluster_number, filename)\n",
    "    kmeans.txt2clusters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-essex",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
